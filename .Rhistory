axis.text.x = element_text(angle = 45, hjust = 1)
) +
scale_fill_brewer(palette = "Set2")
print(grafico_area)
# Crear gr치fico de 치rea con tiempo en minutos y todos los d칤as en el eje X
grafico_area <- ggplot(datos_por_dia, aes(x = fecha_solo, y = tiempo_total, fill = tipo_de_conducta)) +
geom_area(alpha = 0.8) +
theme_minimal() +
labs(
title = "Tiempo de actividad por d칤a y categor칤a de comportamiento",
x = "Fecha",
y = "Tiempo (minutos)", # Cambiado de segundos a minutos
fill = "Tipo de conducta"
) +
scale_x_date(
date_labels = "%d-%m",
date_breaks = "1 day", # Mostrar todos los d칤as
# Asegurar que se muestren las l칤neas verticales para todos los d칤as
limits = c(as.Date("2025-04-06"), as.Date("2025-05-24")),
minor_breaks = NULL
) +
scale_y_continuous(
breaks = seq(0, 220, by = 20) # Ajustado para minutos (aproximadamente equivalente a 1000 segundos)
) +
theme(
legend.position = "bottom",
plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
panel.grid.major.y = element_line(color = "gray90"),
panel.grid.major.x = element_line(color = "gray90"), # Asegurar que las l칤neas de d칤as se vean
panel.grid.minor = element_blank(),
# Rotar las etiquetas de fecha para evitar solapamiento
axis.text.x = element_text(angle = 45, hjust = 1)
) +
scale_fill_brewer(palette = "Set2")
print(grafico_area)
# Crear gr치fico de 치rea con tiempo en minutos y todos los d칤as en el eje X
# Crear gr치fico de 치rea con tiempo en minutos y l칤mites espec칤ficos en el eje X
grafico_area <- ggplot(datos_por_dia, aes(x = fecha_solo, y = tiempo_total, fill = tipo_de_conducta)) +
geom_area(alpha = 0.8) +
theme_minimal() +
labs(
title = "Tiempo de actividad por d칤a y categor칤a de comportamiento",
x = "Fecha",
y = "Tiempo (minutos)",
fill = "Tipo de conducta"
) +
# Establecer l칤mites espec칤ficos para el eje X: desde 6 de abril hasta 24 de mayo
scale_x_date(
date_labels = "%d-%m",
date_breaks = "1 day",
limits = c(as.Date("2025-04-06"), as.Date("2025-05-24")),
minor_breaks = NULL
) +
scale_y_continuous(
breaks = seq(0, 220, by = 20)
) +
theme(
legend.position = "bottom",
plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
panel.grid.major.y = element_line(color = "gray90"),
panel.grid.major.x = element_line(color = "gray90"),
panel.grid.minor = element_blank(),
axis.text.x = element_text(angle = 45, hjust = 1)
) +
scale_fill_brewer(palette = "Set2")
# 5. Mostrar los gr치ficos
# Para visualizar en RStudio
print(grafico_general)
print(grafico_directas)
print(grafico_indirectas)
print(grafico_area)
# Crear gr치fico de 치rea con tiempo en minutos y todos los d칤as en el eje X
grafico_area <- ggplot(datos_por_dia, aes(x = fecha_solo, y = tiempo_total, fill = tipo_de_conducta)) +
geom_area(alpha = 0.8) +
theme_minimal() +
labs(
title = "Tiempo de actividad por d칤a y categor칤a de comportamiento",
x = "Fecha",
y = "Tiempo (minutos)",
fill = "Tipo de conducta"
) +
# Establecer l칤mites espec칤ficos para el eje X: desde 6 de abril hasta 24 de mayo
scale_x_date(
date_labels = "%d-%m",
date_breaks = "1 day",
limits = c(as.Date("2025-04-06"), as.Date("2025-05-24")),
minor_breaks = NULL
) +
scale_y_continuous(
breaks = seq(0, 220, by = 20)
) +
theme(
legend.position = "bottom",
plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
panel.grid.major.y = element_line(color = "gray90"),
panel.grid.major.x = element_line(color = "gray90"),
panel.grid.minor = element_blank(),
axis.text.x = element_text(angle = 45, hjust = 1)
) +
scale_fill_brewer(palette = "Set2")
print(grafico_area)
# Opcionalmente, crear un panel con los 4 gr치ficos
grid.arrange(
grafico_general, grafico_directas,
grafico_indirectas, grafico_area,
ncol = 2, nrow = 2
)
# Crear gr치fico de 치rea con tiempo en minutos y todos los d칤as en el eje X
grafico_area <- ggplot(datos_por_dia, aes(x = fecha_solo, y = tiempo_total, fill = tipo_de_conducta)) +
geom_area(alpha = 0.8) +
theme_minimal() +
labs(
title = "Tiempo de actividad por d칤a y categor칤a de comportamiento",
x = "Fecha",
y = "Tiempo (minutos)", # Cambiado de segundos a minutos
fill = "Tipo de conducta"
) +
scale_x_date(
date_labels = "%d-%m",
date_breaks = "1 day", # Mostrar todos los d칤as
# Asegurar que se muestren las l칤neas verticales para todos los d칤as
limits = c(as.Date("2025-04-06"), as.Date("2025-05-24")),
minor_breaks = NULL
) +
scale_y_continuous(
breaks = seq(0, 220, by = 20) # Ajustado para minutos (aproximadamente equivalente a 1000 segundos)
) +
theme(
legend.position = "bottom",
plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
panel.grid.major.y = element_line(color = "gray90"),
panel.grid.major.x = element_line(color = "gray90"), # Asegurar que las l칤neas de d칤as se vean
panel.grid.minor = element_blank(),
# Rotar las etiquetas de fecha para evitar solapamiento
axis.text.x = element_text(angle = 45, hjust = 1)
) +
scale_fill_brewer(palette = "Set2")
print(grafico_area)
# Instalar writexl si no lo tienes
if (!requireNamespace("writexl", quietly = TRUE)) {
install.packages("writexl")
}
library(writexl)
# Definir la ruta base donde guardar치s los archivos
ruta_base <- "C:/Users/andya/Downloads/"
# Opci칩n 2 (Alternativa): Guardar todos los dataframes como hojas separadas en un solo archivo Excel
lista_dataframes <- list(
"Comportamiento_General" = tiempo_por_comportamiento,
"Observaciones_Directas" = tiempo_directas,
"Observaciones_Indirectas" = tiempo_indirectas,
"Datos_Por_Dia" = datos_por_dia
)
write_xlsx(lista_dataframes, paste0(ruta_base, "resultados_etogramas_completo.xlsx"))
i
# 5. Mostrar los gr치ficos
# Para visualizar en RStudio
print(grafico_general)
print(grafico_directas)
print(grafico_indirectas)
print(grafico_area)
install.packages("rscopus")
# instalar si no lo tienes
# install.packages("rscopus")
library(rscopus)
# tu API Key
api_key <- "1dc409fae8fc67e8c05cfc6e9b9bdebf"
# tu query de prueba (puedes poner la grande o algo m치s simple)
query <- '( TITLE-ABS-KEY ( "climate change" OR "global warming" OR "greenhouse gas*" OR "CO2 emission*" OR "carbon emission*" OR "sea level rise" OR "sea-level rise" OR "heat wave*" OR "heatwave*" OR "extreme heat" OR "drought*" OR "flood*" OR "extreme event*" OR "climat* adapt*" OR "climat* mitigat*" OR "decarboniz*" OR "renewable energy" OR "climate policy" ) ) AND ( LIMIT-TO ( SUBJAREA , "ENVI" ) OR LIMIT-TO ( SUBJAREA , "EART" ) OR LIMIT-TO ( SUBJAREA , "AGRI" ) OR LIMIT-TO ( SUBJAREA , "ENER" ) OR LIMIT-TO ( SUBJAREA , "BIOC" ) OR LIMIT-TO ( SUBJAREA , "CHEM" ) OR LIMIT-TO ( SUBJAREA , "MEDI" ) OR LIMIT-TO ( SUBJAREA , "ECON" ) OR LIMIT-TO ( SUBJAREA , "SOCI" ) ) AND ( LIMIT-TO ( DOCTYPE , "ar" ) OR LIMIT-TO ( DOCTYPE , "re" ) OR LIMIT-TO ( DOCTYPE , "no" ) OR LIMIT-TO ( DOCTYPE , "ed" ) OR LIMIT-TO ( DOCTYPE , "le" ) OR LIMIT-TO ( DOCTYPE , "sh" ) ) AND ( LIMIT-TO ( LANGUAGE , "English" ) OR LIMIT-TO ( LANGUAGE , "Spanish" ) )'
# funci칩n para descargar lote de resultados
get_scopus_sample <- function(query, api_key, n_max = 100, count = 200) {
out <- list()
start <- 0
total_downloaded <- 0
while (total_downloaded < n_max) {
res <- scopus_search(query = query,
api_key = api_key,
view = "COMPLETE",
count = min(count, n_max - total_downloaded),
start = start)
df <- gen_entries_to_df(res$entries)
if (nrow(df) == 0) break
out[[length(out)+1]] <- df
total_downloaded <- total_downloaded + nrow(df)
start <- start + nrow(df)
Sys.sleep(0.5) # pausa para no saturar API
}
do.call(rbind, out)
}
# bajar 100 art칤culos de prueba
df_test <- get_scopus_sample(query, api_key, n_max = 100)
api_key <- "1dc409fae8fc67e8c05cfc6e9b9bdebf"
query <- 'TITLE-ABS-KEY("climate change" OR "global warming")'
get_scopus_sample <- function(query, api_key, n_max = 100, count = 200) {
out <- list()
start <- 0
total_downloaded <- 0
while (total_downloaded < n_max) {
res <- scopus_search(query = query,
api_key = api_key,
view = "STANDARD",   # 游녣 cambio clave aqu칤
count = min(count, n_max - total_downloaded),
start = start)
df <- gen_entries_to_df(res$entries)
if (nrow(df) == 0) break
out[[length(out)+1]] <- df
total_downloaded <- total_downloaded + nrow(df)
start <- start + nrow(df)
Sys.sleep(0.5)
}
do.call(rbind, out)
}
# prueba con 100 art칤culos
df_test <- get_scopus_sample(query, api_key, n_max = 100)
write.csv(df_test, "scopus_test100.csv", row.names = FALSE)
api_key <- "99d6ab6628717280ed162c543de54692"
library(rscopus)
api_key <- "99d6ab6628717280ed162c543de54692"
query <- '( TITLE-ABS-KEY ( "climate change" OR "global warming" OR "greenhouse gas*" OR "CO2 emission*" OR "carbon emission*" OR "sea level rise" OR "sea-level rise" OR "heat wave*" OR "heatwave*" OR "extreme heat" OR "drought*" OR "flood*" OR "extreme event*" OR "climat* adapt*" OR "climat* mitigat*" OR "decarboniz*" OR "renewable energy" OR "climate policy" ) ) AND ( LIMIT-TO ( SUBJAREA , "ENVI" ) OR LIMIT-TO ( SUBJAREA , "EART" ) OR LIMIT-TO ( SUBJAREA , "AGRI" ) OR LIMIT-TO ( SUBJAREA , "ENER" ) OR LIMIT-TO ( SUBJAREA , "BIOC" ) OR LIMIT-TO ( SUBJAREA , "CHEM" ) OR LIMIT-TO ( SUBJAREA , "MEDI" ) OR LIMIT-TO ( SUBJAREA , "ECON" ) OR LIMIT-TO ( SUBJAREA , "SOCI" ) ) AND ( LIMIT-TO ( DOCTYPE , "ar" ) OR LIMIT-TO ( DOCTYPE , "re" ) OR LIMIT-TO ( DOCTYPE , "no" ) OR LIMIT-TO ( DOCTYPE , "ed" ) OR LIMIT-TO ( DOCTYPE , "le" ) OR LIMIT-TO ( DOCTYPE , "sh" ) ) AND ( LIMIT-TO ( LANGUAGE , "English" ) OR LIMIT-TO ( LANGUAGE , "Spanish" ) )'
get_scopus_sample <- function(query, api_key, n_max = 100, count = 200) {
out <- list()
start <- 0
total_downloaded <- 0
while (total_downloaded < n_max) {
res <- scopus_search(query = query,
api_key = api_key,
view = "STANDARD",   # 游녣 cambio clave aqu칤
count = min(count, n_max - total_downloaded),
start = start)
df <- gen_entries_to_df(res$entries)
if (nrow(df) == 0) break
out[[length(out)+1]] <- df
total_downloaded <- total_downloaded + nrow(df)
start <- start + nrow(df)
Sys.sleep(0.5)
}
do.call(rbind, out)
}
# prueba con 100 art칤culos
df_test <- get_scopus_sample(query, api_key, n_max = 100)
get_scopus_sample <- function(query, api_key, n_max = 100, count = 200) {
out <- list()
start <- 0
total_downloaded <- 0
while (total_downloaded < n_max) {
res <- scopus_search(query = query,
api_key = api_key,
view = "STANDARD",   # 游녣 cambio clave aqu칤
count = min(count, n_max - total_downloaded),
start = start)
df <- gen_entries_to_df(res$entries)
if (nrow(df) == 0) break
out[[length(out)+1]] <- df
total_downloaded <- total_downloaded + nrow(df)
start <- start + nrow(df)
Sys.sleep(0.5)
}
do.call(rbind, out)
}
# prueba con 100 art칤culos
df_test <- get_scopus_sample(query, api_key, n_max = 100)
write.csv(df_test, "scopus_test100.csv", row.names = FALSE)
# prueba con 100 art칤culos
df_test <- get_scopus_sample(query, api_key, n_max = 100)
# Instalaci칩n de paquetes necesarios (ejecutar una sola vez
install.packages(c("rscopus", "httr", "dplyr", "tidyr", "jsonlite", "readr"))
# Cargar librer칤as
library(rscopus)
library(httr)
library(dplyr)
library(tidyr)
library(jsonlite)
library(readr)
# Configurar la clave API de Scopus
api_key <- "99d6ab6628717280ed162c543de54692"
set_api_key(api_key)
set_api_key(api_key)
# Funci칩n para extraer datos con manejo de errores
extraer_datos_scopus <- function(query, limite = 50, batch_size = 25) {
cat("Iniciando extracci칩n de", limite, "art칤culos de Scopus...\n")
# Resultados combinados
resultados_completos <- data.frame()
# Calcular n칰mero de lotes
num_lotes <- ceiling(limite / batch_size)
for (i in 1:num_lotes) {
cat(paste0("Procesando lote ", i, " de ", num_lotes, "...\n"))
# Calcular inicio y tama침o del lote
start_idx <- (i - 1) * batch_size
current_batch_size <- min(batch_size, limite - start_idx)
# Intentar la consulta con reintentos
max_intentos <- 3
for (intento in 1:max_intentos) {
tryCatch({
# Realizar la consulta a Scopus
resp <- scopus_search(
query = query,
count = current_batch_size,
start = start_idx,
view = "COMPLETE"
)
if (!is.null(resp) && !is.null(resp$entries)) {
# Extraer los datos de inter칠s
lote_df <- gen_entries_to_df(resp$entries)
# A침adir al conjunto de resultados
if (nrow(resultados_completos) == 0) {
resultados_completos <- lote_df
} else {
resultados_completos <- bind_rows(resultados_completos, lote_df)
}
cat(paste0("  Extra칤dos ", nrow(lote_df), " art칤culos en este lote\n"))
cat(paste0("  Total acumulado: ", nrow(resultados_completos), " de ", limite, " art칤culos\n"))
# Salir del bucle de reintentos
break
} else {
cat("  No se encontraron resultados en este lote\n")
break
}
}, error = function(e) {
cat(paste0("Error en intento ", intento, ": ", e$message, "\n"))
if (intento < max_intentos) {
wait_time <- 2^intento
cat(paste0("Reintentando en ", wait_time, " segundos...\n"))
Sys.sleep(wait_time)
} else {
cat("N칰mero m치ximo de intentos alcanzado para este lote\n")
}
})
}
# Pausa entre lotes para evitar l칤mites de la API
Sys.sleep(1)
# Detener si ya alcanzamos el l칤mite solicitado
if (nrow(resultados_completos) >= limite) {
resultados_completos <- resultados_completos[1:limite, ]
break
}
}
return(resultados_completos)
}
# Funci칩n para extraer y procesar campos espec칤ficos
procesar_resultados <- function(df) {
if (nrow(df) == 0) {
cat("No hay datos para procesar\n")
return(data.frame())
}
# Seleccionar y renombrar columnas relevantes
df_procesado <- df %>%
select(
EID = eid,
DOI = doi,
Title = title,
Year = year,
Journal = `prism:publicationName`,
Volume = volume,
Issue = issue,
Citations = `citedby-count`,
Abstract = `dc:description`,
Authors = `author-names`,
Affiliations = `affiliation-name`
) %>%
# Manejar valores NA
mutate(across(everything(), ~ifelse(is.na(.), "", .)))
return(df_procesado)
}
# Consulta para la prueba (versi칩n reducida)
query_prueba <- 'TITLE-ABS-KEY("climate change" OR "global warming") AND PUBYEAR = 2023 AND (SUBJAREA(ENVI) OR SUBJAREA(EART)) AND (DOCTYPE(ar)) AND (LANGUAGE(English))'
# Ejecutar extracci칩n de prueba
cat("Iniciando prueba de extracci칩n de datos bibliom칠tricos de Scopus...\n")
resultados <- extraer_datos_scopus(query_prueba, limite = 50)
data = read.csv("C:/Users/andya/Downloads/temperature-anomaly-vs-latitude/temperature-anomaly-vs-latitude.csv")
View(data)
unique(data$Entity)
summary(data$Year)
unique(data$Year)
# Eliminar filas con NAs en columna Temperature.anomaly
data2 <- na.omit(data$Temperature.anomaly)
# Eliminar filas con NAs en columna Temperature.anomaly
data2 <- na.omit(data)
# Eliminar filas con NAs en columna Temperature.anomaly
data2 <- na.omit(data)
# Eliminar filas con NAs en la columna Temperature.anomaly de data especificamente
data2 <- data[!is.na(data$Temperature.anomaly), ]
unique(data$Entity)
summary(data$Year)
unique(data2$Entity)
summary(data2$Year)
View(data2)
library(ggplot2)
library(ggplot)
installed.packages(ggplot)
install.packages("ggplot2")
library(ggplot)
library(ggplot2)
# Instalar (si no lo tienes) y cargar data.table, que es m치s r치pido y tolerante a diferencias de columnas
if (!require(data.table)) install.packages("data.table")
library(data.table)
# Definir la carpeta donde est치n tus CSV
setwd("C:/Users/andya/OneDrive/Documentos/ClimateChangeIGC")
# Listar todos los archivos .csv en esa carpeta
archivos <- list.files(pattern = "\\.csv$", full.names = TRUE)
# Leer y combinar todos los CSV (aunque tengan diferentes columnas)
ClimateChangeMetadata <- rbindlist(lapply(archivos, fread), fill = TRUE)
# Guardar el resultado en un 칰nico archivo
fwrite(ClimateChangeMetadata, "ClimateChangeMetadata.csv")
# Guardar en la misma carpeta donde estaban los CSV originales
fwrite(ClimateChangeMetadata,
"C:/Users/andya/OneDrive/Documentos/ClimateChangeIGC/ClimateChangeMetadata.csv")
View(ClimateChangeMetadata)
# Instalar (si no lo tienes) y cargar data.table, que es m치s r치pido y tolerante a diferencias de columnas
if (!require(data.table)) install.packages("data.table")
library(data.table)
# Definir la carpeta donde est치n tus CSV
setwd("C:/Users/andya/OneDrive/Documentos/ClimateChangeIGC")
# Listar todos los archivos .csv en esa carpeta
archivos <- list.files(pattern = "\\.csv$", full.names = TRUE)
# Leer y combinar todos los CSV (aunque tengan diferentes columnas)
ClimateChangeMetadata <- rbindlist(lapply(archivos, fread), fill = TRUE)
# Guardar el resultado en un 칰nico archivo
fwrite(ClimateChangeMetadata, "ClimateChangeMetadata.csv")
# Guardar en la misma carpeta donde estaban los CSV originales
fwrite(ClimateChangeMetadata,
"C:/Users/andya/OneDrive/Documentos/ClimateChangeIGC/ClimateChangeMetadata.csv")
View(ClimateChangeMetadata)
head(ClimateChangeMetadata, 20)
ClimateChangeMetadata()
ClimateChangeMetadata
ClimateChangeMetadata <- fread("C:/Users/andya/OneDrive/Documentos/ClimateChangeIGC/ClimateChangeMetadata.csv")
nrow(ClimateChangeMetadata)
head(ClimateChangeMetadata$Affiliations)
# Cargar las librer칤as necesarias
library(data.table)  # Para procesamiento eficiente en datasets grandes
library(stringr)     # Para manipulaci칩n de cadenas
# Lista completa de pa칤ses en ingl칠s
paises <- c(
"Afghanistan", "Albania", "Algeria", "Andorra", "Angola", "Antigua and Barbuda",
"Argentina", "Armenia", "Australia", "Austria", "Azerbaijan", "Bahamas", "Bahrain",
"Bangladesh", "Barbados", "Belarus", "Belgium", "Belize", "Benin", "Bhutan",
"Bolivia", "Bosnia and Herzegovina", "Botswana", "Brazil", "Brunei", "Bulgaria",
"Burkina Faso", "Burundi", "Cabo Verde", "Cambodia", "Cameroon", "Canada",
"Central African Republic", "Chad", "Chile", "China", "Colombia", "Comoros",
"Congo", "Costa Rica", "Croatia", "Cuba", "Cyprus", "Czech Republic",
"Democratic Republic of the Congo", "Denmark", "Djibouti", "Dominica",
"Dominican Republic", "East Timor", "Ecuador", "Egypt", "El Salvador",
"Equatorial Guinea", "Eritrea", "Estonia", "Eswatini", "Ethiopia", "Fiji",
"Finland", "France", "Gabon", "Gambia", "Georgia", "Germany", "Ghana", "Greece",
"Grenada", "Guatemala", "Guinea", "Guinea-Bissau", "Guyana", "Haiti", "Honduras",
"Hungary", "Iceland", "India", "Indonesia", "Iran", "Iraq", "Ireland", "Israel",
"Italy", "Ivory Coast", "Jamaica", "Japan", "Jordan", "Kazakhstan", "Kenya",
"Kiribati", "Kuwait", "Kyrgyzstan", "Laos", "Latvia", "Lebanon", "Lesotho",
"Liberia", "Libya", "Liechtenstein", "Lithuania", "Luxembourg", "Madagascar",
"Malawi", "Malaysia", "Maldives", "Mali", "Malta", "Marshall Islands", "Mauritania",
"Mauritius", "Mexico", "Micronesia", "Moldova", "Monaco", "Mongolia", "Montenegro",
"Morocco", "Mozambique", "Myanmar", "Namibia", "Nauru", "Nepal", "Netherlands",
"New Zealand", "Nicaragua", "Niger", "Nigeria", "North Korea", "North Macedonia",
"Norway", "Oman", "Pakistan", "Palau", "Palestine", "Panama", "Papua New Guinea",
"Paraguay", "Peru", "Philippines", "Poland", "Portugal", "Qatar", "Romania",
"Russia", "Rwanda", "Saint Kitts and Nevis", "Saint Lucia",
"Saint Vincent and the Grenadines", "Samoa", "San Marino", "Sao Tome and Principe",
"Saudi Arabia", "Senegal", "Serbia", "Seychelles", "Sierra Leone", "Singapore",
"Slovakia", "Slovenia", "Solomon Islands", "Somalia", "South Africa", "South Korea",
"South Sudan", "Spain", "Sri Lanka", "Sudan", "Suriname", "Sweden", "Switzerland",
"Syria", "Taiwan", "Tajikistan", "Tanzania", "Thailand", "Togo", "Tonga",
"Trinidad and Tobago", "Tunisia", "Turkey", "Turkmenistan", "Tuvalu", "Uganda",
"Ukraine", "United Arab Emirates", "United Kingdom", "United States", "Uruguay",
"Uzbekistan", "Vanuatu", "Vatican City", "Venezuela", "Vietnam", "Yemen", "Zambia",
"Zimbabwe", "USA", "UK", "UAE", "Republic of Korea", "Republic of China",
"Hong Kong", "Puerto Rico", "Northern Ireland", "Scotland", "Wales"
)
# Crear una expresi칩n regular que busque cualquier pa칤s al final de una cadena
# El patr칩n busca una coma seguida de espacios y luego cualquiera de los pa칤ses en la lista
patron_paises <- paste0(",\\s*(?:", paste(paises, collapse = "|"), ")$")
# Funci칩n optimizada para extraer el pa칤s usando funciones de data.table
extraer_pais <- function(aff) {
# Si la afiliaci칩n est치 vac칤a, devolver NA
if (is.na(aff) || aff == "") return(NA_character_)
# Extraer la primera afiliaci칩n (antes del primer punto y coma)
primera_aff <- unlist(strsplit(aff, ";"))[1]
if (is.null(primera_aff) || primera_aff == "") return(NA_character_)
# Extraer el pa칤s (칰ltimo segmento despu칠s de la 칰ltima coma)
partes <- unlist(strsplit(primera_aff, ","))
if (length(partes) < 1) return(NA_character_)
pais <- trimws(partes[length(partes)])
# Comprobar si el pa칤s extra칤do est치 en nuestra lista
for (p in paises) {
if (pais == p) return(pais)
}
# Si el pa칤s extra칤do no est치 en la lista, buscar si contiene un pa칤s
for (p in paises) {
if (grepl(p, pais, fixed = TRUE)) return(p)
}
# Si no se encuentra un pa칤s exacto, devolver el texto extra칤do
return(pais)
}
# Convertir a data.table para procesamiento m치s r치pido
setDT(ClimateChangeMetadata)
# Aplicar la funci칩n usando data.table para mayor eficiencia
ClimateChangeMetadata[, Pais_Primer_Autor := sapply(Affiliations, extraer_pais)]
# Ver algunos resultados para verificar
head(ClimateChangeMetadata[, .(Affiliations, Pais_Primer_Autor)], 10)
ClimateChangeMetadata <- fread("C:/Users/andya/OneDrive/Documentos/ClimateChangeIGC/data")
ClimateChangeMetadata <- fread("C:/Users/andya/OneDrive/Documentos/ClimateChangeIGC/data/ClimateChangeMetadata.csv")
View(ClimateChangeMetadata)
setDT(ClimateChangeMetadata)   # asegurar data.table
backup_ClimateChangeMetadata <- copy(ClimateChangeMetadata)
# n칰mero total de filas y n칰mero de filas 칰nicas
total_rows <- nrow(ClimateChangeMetadata)
unique_rows <- uniqueN(ClimateChangeMetadata)   # uniqueN es r치pido
unique_rows <- uniqueN(ClimateChangeMetadata)   # uniqueN es r치pido
library(data.table)
setDT(ClimateChangeMetadata)   # asegurar data.table
backup_ClimateChangeMetadata <- copy(ClimateChangeMetadata)
# n칰mero total de filas y n칰mero de filas 칰nicas
total_rows <- nrow(ClimateChangeMetadata)
unique_rows <- uniqueN(ClimateChangeMetadata)   # uniqueN es r치pido
